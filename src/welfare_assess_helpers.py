import os
import glob
import re
import numpy as np
import cv2
import base64
import pandas as pd
from datetime import datetime
import json
import time
import requests
from moviepy.editor import VideoFileClip, AudioFileClip, CompositeAudioClip
from PIL import Image
from io import BytesIO
import re


def convert_images_to_base64(folder_path, all_files):
    
    all_images = []
    for f in all_files:
        file_path = os.path.join(folder_path, f)
        if f.lower().endswith('.png'):
            # Convert PNG images to JPEG and then to Base64
            base64_string = convert_to_jpeg_base64(file_path)
        elif f.lower().endswith(('.jpg', '.jpeg')):
            # Convert JPG images directly to Base64
            base64_string = convert_jpg_to_base64(file_path)
        all_images.append(base64_string)
    
    return all_images


def convert_to_jpeg_base64(png_image_path):
    # Open the PNG image
    with Image.open(png_image_path) as img:
        # Convert to JPEG
        buffer = BytesIO()
        img.convert('RGB').save(buffer, format="JPEG")
        # Encode to Base64
        jpeg_base64 = base64.b64encode(buffer.getvalue()).decode()
    return jpeg_base64

def convert_jpg_to_base64(jpg_image_path):
    # Open the JPG image
    with Image.open(jpg_image_path) as img:
        # Create a BytesIO object to hold the byte stream
        buffer = BytesIO()
        
        # Save the image to the buffer
        img.save(buffer, format="JPEG")
        
        # Get the byte stream and encode it to Base64
        base64_string = base64.b64encode(buffer.getvalue()).decode()

    return base64_string

def generate_image_content_with_description(all_images, all_files, detail_level="low"):
    content = []
    for image_index in range(0, len(all_images)):
        cur_file = all_files[image_index]
        cur_image = all_images[image_index]

        parts = cur_file.split('_')
        example_description = "\nExample image of a cow assessed as " + parts[0] + " " + parts[1] + ": \n"

        content.append({"type": "text", "text": example_description})
        content.append({
            "type": "image_url",
            "image_url": {
                "url": f"data:image/jpg;base64, {cur_image}",
                "detail": detail_level
            }
        })

    return content

def prompt_welfare_assess_test_image(client, system_prompt, user_prompt1, user_prompt2, train_images, train_files, cur_test, detail_level, max_tokens, s, temp):
    # Generate the content for the train images
    train_content = generate_image_content_with_description(train_images, train_files, detail_level=detail_level)

    # Constructing prompt messages
    prompt_messages = [
        {
            "role": "system",
            "content": system_prompt
        },
        {
            "role": "user",
            "content": [
                {"type": "text", "text": user_prompt1},
                *train_content,  # Using the list of dictionaries generated by the function
                {"type": "text", "text": user_prompt2},
                {"type": "image_url",
                 "image_url": {
                    "url": f"data:image/jpg;base64, {cur_test}",
                    "detail": detail_level}
                }
            ],
        },
    ]

    # Parameters for the API call
    params = {
        "model": "gpt-4o",
        "messages": prompt_messages,
        "max_tokens": max_tokens,
        "seed": s,
        "temperature": temp
    }

    # Assuming client.chat.completions.create is a function call to an external API
    result = client.chat.completions.create(**params)
    print(result.choices[0].message.content)  # print out the response
    print(result.usage)  # print out how many tokens were used

    return result



def save_results_to_csv(full_path, cur_file_name, result, system_prompt, user_prompt, max_tokens, detail_level, seed, temperature, body_type, treatment):
    

    # extract the true label of the image
    parts = re.split(r'[_.]', cur_file_name)
    true_score = parts[0]  
    true_note = parts[1]

    # extract content from result
    result_content = result.choices[0].message.content
    result_json = result_content.strip('```json\n').strip('```')
    json_data = json.loads(result_json) # Convert the string to a Python dictionary
    predict_score = json_data.get('assessment_result', 'NA')
    conf = json_data.get('confidence', 'NA')
    reason = json_data.get('reason', 'NA')

    # calculate usage
    output_token = result.usage.completion_tokens
    prompt_tokens = result.usage.prompt_tokens
    output_token_p = output_token_cost(output_token)
    prompt_tokens_p = input_token_cost(prompt_tokens)
    total_cost = round((output_token_p+prompt_tokens_p), 3)

    data = {
        "test_image": cur_file_name,
        "assess_area": body_type,
        "treatment": treatment,
        "true_score": true_score,
        "true_note": true_note,
        "predict_score": predict_score,
        "predict_confidence": conf,
        "predict_reason": reason,
        "predict_result": result,
        "model": "gpt-4o",
        "date": datetime.now().date(),
        "system_prompt": system_prompt,
        "user_prompt": user_prompt,
        "max_tokens": max_tokens,
        "detail_level": detail_level,
        "seed": seed,
        "temperature": temperature,
        "completion_tokens": output_token,
        "prompt_tokens": prompt_tokens,
        "total_cost": total_cost

    }

    df = pd.DataFrame([data])

    if os.path.isfile(full_path):
        df.to_csv(full_path, mode='a', header=False, index=False)
        print(f"Data appended to {full_path}")
    else:
        df.to_csv(full_path, mode='w', header=True, index=False)
        print(f"Data written to {full_path}")

def test_images_in_range(full_path, start_index, end_index, client, system_prompt, user_prompt1, user_prompt2, train_images, train_files, test_images, test_files, detail_level, max_tokens, s, temp, body_type, treatment):
    user_prompt = user_prompt1 + "\n**example images**\n" + user_prompt2 + "\n**test images**\n"
    for i in range(start_index, end_index):
        cur_file_name = test_files[i]
        cur_image = test_images[i]
        result = prompt_welfare_assess_test_image(client, system_prompt, user_prompt1, user_prompt2, train_images, train_files, cur_image, detail_level, max_tokens, s, temp)
        save_results_to_csv(full_path, cur_file_name, result, system_prompt, user_prompt, max_tokens, detail_level, s, temp, body_type, treatment)